{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA DFS Backtest Runner\n",
    "\n",
    "Walk-forward backtesting for NBA DFS projections with flexible feature engineering.\n",
    "\n",
    "**Data Source**: SQLite database at `nba_dfs.db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NBA DFS BACKTEST NOTEBOOK\n",
      "================================================================================\n",
      "Initialized successfully\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.evaluation.backtest_config import BacktestConfig\n",
    "from src.evaluation.walk_forward import WalkForwardBacktest\n",
    "from src.evaluation.analysis import generate_backtest_report\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print('=' * 80)\n",
    "print('NBA DFS BACKTEST NOTEBOOK')\n",
    "print('=' * 80)\n",
    "print('Initialized successfully')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Single Window\n",
    "\n",
    "Baseline with 4-game rolling window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_standard = BacktestConfig(\n",
    "    start_date='20250102',\n",
    "    end_date='20250110',\n",
    "    lookback_days=60,\n",
    "    model_type='xgboost',\n",
    "    rolling_window_sizes=[3,10]\n",
    ")\n",
    "\n",
    "print(f\"Rolling Windows: {config_standard.rolling_window_sizes}\")\n",
    "print(f\"Features: {len(config_standard.features_to_use)}\")\n",
    "\n",
    "backtest = WalkForwardBacktest(config_standard, db_path='../nba_dfs.db')\n",
    "results_standard = backtest.run()\n",
    "\n",
    "if 'error' not in results_standard:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RESULTS - STANDARD FEATURES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"MAPE: {results_standard['mean_mape']:.1f}%\")\n",
    "    print(f\"RMSE: {results_standard['mean_rmse']:.2f}\")\n",
    "    print(f\"Correlation: {results_standard['mean_correlation']:.3f}\")\n",
    "    print(f\"Slates: {results_standard['num_slates']}\")\n",
    "else:\n",
    "    print(f\"ERROR: {results_standard['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Dual Window\n",
    "\n",
    "Window-based features with 4 and 10-game windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_rolling = BacktestConfig(\n",
    "    start_date='20231101',\n",
    "    end_date='20231130',\n",
    "    lookback_days=90,\n",
    "    model_type='xgboost',\n",
    "    rolling_window_sizes=[4, 10]\n",
    ")\n",
    "\n",
    "print(f\"Rolling Windows: {config_rolling.rolling_window_sizes}\")\n",
    "print(f\"Features: {len(config_rolling.features_to_use)}\")\n",
    "\n",
    "backtest = WalkForwardBacktest(config_rolling, db_path='../nba_dfs.db')\n",
    "results_rolling = backtest.run()\n",
    "\n",
    "if 'error' not in results_rolling:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RESULTS - ROLLING WINDOW FEATURES (4g)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"MAPE: {results_rolling['mean_mape']:.1f}%\")\n",
    "    print(f\"RMSE: {results_rolling['mean_rmse']:.2f}\")\n",
    "    print(f\"Correlation: {results_rolling['mean_correlation']:.3f}\")\n",
    "    print(f\"Slates: {results_rolling['num_slates']}\")\n",
    "else:\n",
    "    print(f\"ERROR: {results_rolling['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Multiple Windows\n",
    "\n",
    "Test multiple temporal perspectives: [3, 4, 5, 10] games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_multi = BacktestConfig(\n",
    "    start_date='20231101',\n",
    "    end_date='20231130',\n",
    "    lookback_days=90,\n",
    "    model_type='xgboost',\n",
    "    rolling_window_sizes=[3, 4, 5, 10]\n",
    ")\n",
    "\n",
    "print(f\"Rolling Windows: {config_multi.rolling_window_sizes}\")\n",
    "print(f\"Features: {len(config_multi.features_to_use)}\")\n",
    "\n",
    "backtest = WalkForwardBacktest(config_multi, db_path='../nba_dfs.db')\n",
    "results_multi = backtest.run()\n",
    "\n",
    "if 'error' not in results_multi:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RESULTS - MULTIPLE WINDOWS [3,4,5,10]\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"MAPE: {results_multi['mean_mape']:.1f}%\")\n",
    "    print(f\"RMSE: {results_multi['mean_rmse']:.2f}\")\n",
    "    print(f\"Correlation: {results_multi['mean_correlation']:.3f}\")\n",
    "    print(f\"Slates: {results_multi['num_slates']}\")\n",
    "else:\n",
    "    print(f\"ERROR: {results_multi['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Single Window Baseline\n",
    "\n",
    "Single 4-game window as baseline comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_combined = BacktestConfig(\n",
    "    start_date='20231101',\n",
    "    end_date='20231130',\n",
    "    lookback_days=90,\n",
    "    model_type='xgboost',\n",
    "    rolling_window_sizes=[4]\n",
    ")\n",
    "\n",
    "print(f\"Rolling Windows: {config_combined.rolling_window_sizes}\")\n",
    "print(f\"Total Features: {len(config_combined.features_to_use)}\")\n",
    "\n",
    "backtest = WalkForwardBacktest(config_combined, db_path='../nba_dfs.db')\n",
    "results_combined = backtest.run()\n",
    "\n",
    "if 'error' not in results_combined:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RESULTS - COMBINED FEATURES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"MAPE: {results_combined['mean_mape']:.1f}%\")\n",
    "    print(f\"RMSE: {results_combined['mean_rmse']:.2f}\")\n",
    "    print(f\"Correlation: {results_combined['mean_correlation']:.3f}\")\n",
    "    print(f\"Slates: {results_combined['num_slates']}\")\n",
    "else:\n",
    "    print(f\"ERROR: {results_combined['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Compare all feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results = []\n",
    "\n",
    "if 'error' not in results_standard:\n",
    "    comparison_results.append({\n",
    "        'name': 'Standard',\n",
    "        'mape': results_standard['mean_mape'],\n",
    "        'rmse': results_standard['mean_rmse'],\n",
    "        'correlation': results_standard['mean_correlation']\n",
    "    })\n",
    "\n",
    "if 'error' not in results_rolling:\n",
    "    comparison_results.append({\n",
    "        'name': 'Rolling (4g)',\n",
    "        'mape': results_rolling['mean_mape'],\n",
    "        'rmse': results_rolling['mean_rmse'],\n",
    "        'correlation': results_rolling['mean_correlation']\n",
    "    })\n",
    "\n",
    "if 'error' not in results_multi:\n",
    "    comparison_results.append({\n",
    "        'name': 'Multi-Window',\n",
    "        'mape': results_multi['mean_mape'],\n",
    "        'rmse': results_multi['mean_rmse'],\n",
    "        'correlation': results_multi['mean_correlation']\n",
    "    })\n",
    "\n",
    "if 'error' not in results_combined:\n",
    "    comparison_results.append({\n",
    "        'name': 'Combined',\n",
    "        'mape': results_combined['mean_mape'],\n",
    "        'rmse': results_combined['mean_rmse'],\n",
    "        'correlation': results_combined['mean_correlation']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FEATURE SET COMPARISON\")\n",
    "print(f\"{'='*80}\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Compare MAPE across feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(comparison_results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    names = [r['name'] for r in comparison_results]\n",
    "    mapes = [r['mape'] for r in comparison_results]\n",
    "    rmses = [r['rmse'] for r in comparison_results]\n",
    "    \n",
    "    axes[0].bar(names, mapes, color=['#2E86AB', '#A23B72', '#F18F01', '#06A77D'])\n",
    "    axes[0].axhline(y=30, color='red', linestyle='--', linewidth=2, label='30% Target')\n",
    "    axes[0].set_ylabel('MAPE (%)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Prediction Accuracy by Feature Set', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    axes[1].bar(names, rmses, color=['#2E86AB', '#A23B72', '#F18F01', '#06A77D'])\n",
    "    axes[1].set_ylabel('RMSE (points)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Prediction Error by Feature Set', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    best_idx = np.argmin(mapes)\n",
    "    print(f\"\\nBest Feature Set: {names[best_idx]}\")\n",
    "    print(f\"MAPE: {mapes[best_idx]:.1f}%\")\n",
    "    print(f\"RMSE: {rmses[best_idx]:.2f}\")\n",
    "else:\n",
    "    print(\"No comparison results to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Results and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*80}\")\n",
    "print(\"BACKTEST SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(\"Experiments Run:\")\n",
    "print(\"1. Single Window [4] - 4-game rolling window\")\n",
    "print(\"2. Dual Window [4,10] - Short and long window features\")\n",
    "print(\"3. Multiple Windows [3,4,5,10] - Multi-temporal perspectives\")\n",
    "print(\"4. Single Window Baseline - 4-game window only\\n\")\n",
    "\n",
    "print(\"Next Steps:\")\n",
    "print(\"1. Run full season backtest for production validation\")\n",
    "print(\"2. Add DvP and Vegas line features\")\n",
    "print(\"3. Implement lineup optimization\")\n",
    "print(\"4. Check feature importance\\n\")\n",
    "\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
